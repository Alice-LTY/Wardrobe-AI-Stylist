import requests
from bs4 import BeautifulSoup
from backend.utils.nlp import translate_text, translate_color, convert_currency, map_subcategory_to_category  # âœ… æ–°å¢ translate_color
from backend.utils.image_handler import (
    upgrade_image_url_to_high_quality,
    download_product_images
)
import re

def scrape_product_page(url):
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        }
        if "https" not in url:
            url = url.lower()
            url = "https://www.grail.bz/disp/item/"+ url +"/"
        response = requests.get(url, headers=headers)
        if response.status_code != 200:
            return {"error": f"Failed to fetch the webpage. Status code: {response.status_code}"}
        
        soup = BeautifulSoup(response.text, "html.parser")

        # æå–å•†å“åç¨±å’Œè²¨è™Ÿ
        title_section = soup.find("h1", class_="ttl-name")
        if not title_section:
            return {"error": "Product details not found on the page."}
        
        title = title_section.text.strip()
        title_translated = translate_text(title) if title else title  # ç¿»è­¯å•†å“åç¨±
        product_code = title_section.find("span", class_="txt-code").text.strip("[]").lower()  # âœ… çµ±ä¸€è½‰æ›ç‚ºå°å¯«

        # æå–æ¨è–¦åœ–ç‰‡ä¸¦ç¯©é¸é¡è‰²åœ–ç‰‡
        recommendation_images = []
        color_images = []
        color_urls = set()  # ç”¨ä¾†éæ¿¾é¡è‰²åœ–ç‰‡

        recommendation_section = soup.select("div.modal-detaillist img")  # å®šä½æ¨è–¦åœ–ç‰‡å€å¡Š

        for img_tag in recommendation_section:
            img_url = img_tag.get("src", "").strip()
            alt_text = img_tag.get("alt", "").strip()  # æå–é¡è‰²åç¨±
            if img_url:
                # ğŸ”¥ å‡ç´šç‚ºé«˜ç•«è³ª URL
                img_url = upgrade_image_url_to_high_quality(img_url)
                
                # åˆ¤æ–·æ˜¯å¦ç‚ºé¡è‰²åœ–ç‰‡ï¼ˆ`col_xx`ï¼‰
                if "col" in img_url and alt_text:
                    # âœ… ä½¿ç”¨æ–°çš„ translate_color å‡½æ•¸ï¼ˆå„ªå…ˆæŸ¥æ‰¾æ˜ å°„è¡¨ï¼‰
                    color_name_translated = translate_color(alt_text)
                    color_data = {"color": color_name_translated, "image_url": img_url}
                    if img_url not in color_urls:
                        color_images.append(color_data)
                        color_urls.add(img_url)
                else:
                    # å¦‚æœä¸æ˜¯é¡è‰²åœ–ç‰‡ï¼ŒåŠ å…¥æ¨è–¦åˆ—è¡¨
                    recommendation_images.append(img_url)

        # å¾æ¨è–¦åœ–ç‰‡ä¸­ç§»é™¤å·²ç¶“åŠ å…¥é¡è‰²çš„åœ–ç‰‡
        recommendation_images = [img for img in recommendation_images if img not in color_urls]

        # æå–å•†å“è©³ç´°
        product_detail = ""
        material = ""

        detail_sections = soup.find_all("div", class_="tab-content")
        for section in detail_sections:
            header = section.find("h2", class_="contents-ttl only-pc")
            if header:
                header_text = header.get_text(strip=True)
                if "å•†å“è©³ç´°" in header_text:
                    product_detail = section.get_text(strip=True)
                    product_detail = translate_text(product_detail) if product_detail else product_detail
                elif "ã‚µã‚¤ã‚ºãƒ»ç´ æ" in header_text:
                    material = section.get_text(strip=False)
                    material_match = re.search(r'â˜†ç´ æã¯ã€.*?ã€‘', material)
                    if material_match:
                        material = material_match.group(0)
                        material = material.replace('\r', '').replace('\n', '').strip()
                        material = translate_text(material) if material else material
                    else:
                        material = None

        # æå–æ‰€æœ‰å¯é¸å°ºå¯¸
        sizes = set()  # ä½¿ç”¨ set é¿å…é‡è¤‡
        size_options = soup.select("select.size-select option")
        for option in size_options:
            size_text = option.text.strip().split("/")[0]  # åªå– S/M/Lï¼Œä¸å–åº«å­˜è³‡è¨Š
            if size_text:
                sizes.add(size_text)

        # å¦‚æœä»»ä¸€å…ƒç´ åŒ…å« "cm"ï¼Œå‰‡èªç‚ºæ˜¯é‹å­å°ºå¯¸
        if any("cm" in s for s in sizes):
            size_order = ["22.0cm", "22.5cm", "23.0cm", "23.5cm", "24.0cm", "24.5cm", "25.0cm"]
            sizes = sorted(list(sizes), key=lambda x: size_order.index(x) if x in size_order else len(size_order))
        else:
            size_order = ["F", "XS", "S", "M", "L", "XL"]
            sizes = sorted(list(sizes), key=lambda x: size_order.index(x) if x in size_order else len(size_order))
       
        # æå–åƒ¹æ ¼
        price_section = soup.find("p", class_="txt-price")
        if price_section:
            price_text = price_section.text.strip()
            match = re.search(r"Â¥\s?([\d,]+)", price_text)  # æ›´æ–°æ­£å‰‡ï¼Œæ”¯æŒåŒ…å«é€—è™Ÿçš„åƒ¹æ ¼
            if match:
                price_jpy_str = match.group(1).replace(",", "")  # ç§»é™¤åƒåˆ†ä½é€—è™Ÿ
                price_jpy = int(price_jpy_str)  # å°‡æ¸…ç†å¾Œçš„åƒ¹æ ¼è½‰ç‚ºæ•´æ•¸
                price_twd = convert_currency(price_jpy)  # âœ… ä½¿ç”¨ utils/nlp.py çš„å‡½æ•¸è½‰æ›å°å¹£
            else:
                print(f"Price text did not match regex: {price_text}")  # âœ… èª¿è©¦ç”¨
                price_jpy = None
                price_twd = None
        else:
            print("Price section not found in the page")  # âœ… èª¿è©¦ç”¨
            price_jpy = None
            price_twd = None

        # æå–åˆ†é¡
        breadcrumb_items = soup.select(".list-breadcrumb li a")
        if len(breadcrumb_items) >= 3:
            category = breadcrumb_items[1].text.strip()  # ä¸»åˆ†é¡ï¼ˆç¬¬äºŒå€‹é …ç›®ï¼‰
            subcategory = breadcrumb_items[2].text.strip()  # æ¬¡åˆ†é¡ï¼ˆç¬¬ä¸‰å€‹é …ç›®ï¼‰
            subcategory = map_subcategory_to_category(category, subcategory, title)    # ä½¿ç”¨ map_subcategory_to_category ä¿®æ­£å­é¡åˆ¥
            print(f"ğŸ“Œ çˆ¬å–åˆ†é¡: {category} -> {subcategory}")
        elif len(breadcrumb_items) >= 2:
            category = breadcrumb_items[1].text.strip()  # åªæœ‰ä¸»åˆ†é¡
            subcategory = None
            print(f"ğŸ“Œ çˆ¬å–åˆ†é¡: {category} -> None")
        if category == "æµ´è¡£":
            category = "ãƒ¯ãƒ³ãƒ”ãƒ¼ã‚¹"
            subcategory = "æµ´è¡£"
            print(f"ğŸ“Œ èª¿æ•´åˆ†é¡: {category} -> {subcategory}")
        
        # ğŸ”¥ å¯é¸ï¼šä¸‹è¼‰å•†å“åœ–ç‰‡åˆ°æœ¬åœ°ï¼ˆé«˜ç•«è³ªç‰ˆæœ¬ï¼‰
        # å–æ¶ˆä¸‹é¢çš„è¨»è§£ä»¥å•Ÿç”¨è‡ªå‹•ä¸‹è¼‰
        # download_result = download_product_images(product_code, color_images, save_to_backup=True)
        # print(f"ğŸ“¥ åœ–ç‰‡ä¸‹è¼‰çµæœ: {download_result['downloaded']}/{download_result['total_colors']} æˆåŠŸ")
        
        # çµ„åˆè¿”å›çµæœ
        return {
            "title": (title_translated+"ï¼ˆ"+title+"ï¼‰"),
            "product_code": product_code,
            "product_url": url,
            "colors": color_images,
            "colors_opt": [c["color"] for c in color_images],
            "recommendations": recommendation_images,
            "product_detail": product_detail,
            "material": material,
            "sizes": sizes, 
            "price_jpy": price_jpy,  # âœ… æ—¥å¹£åƒ¹æ ¼
            "price_twd": price_twd,  # âœ… å°å¹£åƒ¹æ ¼
            # "url": url,
            "category": category,
            "subcategory": subcategory
        }
    except Exception as e:
        return {"error": str(e)}

# # # æ¸¬è©¦ç¨‹å¼
# url = "https://www.grail.bz/item/dk9881112/?s=2"  # æ›¿æ›ç‚ºå¯¦éš›å•†å“ç¶²å€
# product_data = scrape_product_page(url)
# print(product_data)
