"""
åœ–ç‰‡è™•ç†æ¨¡çµ„ - å„ªåŒ– GRL å•†å“åœ–ç‰‡è™•ç†
åŠŸèƒ½ï¼š
1. å°‡å°åƒç´ åœ–ç‰‡ URL è½‰æ›ç‚ºé«˜ç•«è³ª URL
2. ä¸‹è¼‰åœ–ç‰‡åˆ°æœ¬åœ°å¿«å–
3. æ”¯æ´åœ–ç‰‡å‚™ä»½åˆ°é›²ç«¯ï¼ˆCloudinary/Imgurï¼‰
4. ç‚ºäºŒæ‰‹è½‰å”®æº–å‚™é«˜å“è³ªåœ–ç‰‡
"""

import os
import requests
import re
from pathlib import Path
from typing import Optional, Dict, List
from datetime import datetime
import hashlib

# åœ–ç‰‡å¿«å–ç›®éŒ„ï¼ˆç›¸å°æ–¼å°ˆæ¡ˆæ ¹ç›®éŒ„ï¼‰
IMAGE_CACHE_DIR = Path("images/cache")
IMAGE_BACKUP_DIR = Path("images/backup")


def ensure_image_directories():
    """ç¢ºä¿åœ–ç‰‡ç›®éŒ„å­˜åœ¨"""
    IMAGE_CACHE_DIR.mkdir(parents=True, exist_ok=True)
    IMAGE_BACKUP_DIR.mkdir(parents=True, exist_ok=True)
    print(f"âœ… åœ–ç‰‡ç›®éŒ„å·²æº–å‚™: {IMAGE_CACHE_DIR.absolute()}")


def upgrade_image_url_to_high_quality(img_url: str) -> str:
    """
    å°‡ GRL å°åƒç´ åœ–ç‰‡ URL å‡ç´šç‚ºé«˜ç•«è³ª URL
    
    GRL åœ–ç‰‡ URL æ ¼å¼åˆ†æï¼š
    - ä½ç•«è³ª: https://cdn.grail.bz/images/goods/t/dk988/dk988_v1.jpg (/t/ è·¯å¾‘)
    - é«˜ç•«è³ª: https://cdn.grail.bz/images/goods/d/dk988/dk988_v1.jpg (/d/ è·¯å¾‘)
    - èˆŠæ ¼å¼å°åœ–: https://img.grail.bz/item/GRL-S3225/col_01_150x150.jpg
    - èˆŠæ ¼å¼ä¸­åœ–: https://img.grail.bz/item/GRL-S3225/col_01_300x300.jpg
    - èˆŠæ ¼å¼å¤§åœ–: https://img.grail.bz/item/GRL-S3225/col_01.jpg (åŸåœ–)
    
    åƒæ•¸:
        img_url: åŸå§‹åœ–ç‰‡ URLï¼ˆå¯èƒ½æ˜¯å°åƒç´ ï¼‰
    
    è¿”å›:
        é«˜ç•«è³ªåœ–ç‰‡ URL
    """
    if not img_url:
        return img_url
    
    # æ­¥é©Ÿ 1: å°‡ /t/ è·¯å¾‘æ›¿æ›ç‚º /d/ è·¯å¾‘ï¼ˆæ–°ç‰ˆ CDN æ ¼å¼ï¼‰
    # ä¾‹å¦‚: /images/goods/t/dk988/ -> /images/goods/d/dk988/
    high_quality_url = img_url.replace('/images/goods/t/', '/images/goods/d/')
    
    # æ­¥é©Ÿ 2: ç§»é™¤å°ºå¯¸å¾Œç¶´ï¼ˆèˆŠæ ¼å¼ï¼š_150x150, _300x300 ç­‰ï¼‰
    # åŒ¹é…æ¨¡å¼: _æ•¸å­—xæ•¸å­—.jpg
    high_quality_url = re.sub(r'_\d+x\d+(\.\w+)$', r'\1', high_quality_url)
    
    # åªåœ¨æœ‰è®Šæ›´æ™‚æ‰é¡¯ç¤ºè¨Šæ¯
    if high_quality_url != img_url:
        print(f"ğŸ”„ åœ–ç‰‡å‡ç´š: {os.path.basename(img_url)} -> {os.path.basename(high_quality_url)}")
    
    return high_quality_url


def construct_image_url_from_product_code(
    product_code: str, 
    color_code: str = "01",
    high_quality: bool = True
) -> str:
    """
    æ ¹æ“šå•†å“ä»£ç¢¼å’Œé¡è‰²ä»£ç¢¼æ§‹å»ºåœ–ç‰‡ URL
    å³ä½¿å•†å“é é¢å¤±æ•ˆï¼Œä»èƒ½å–å¾—åœ–ç‰‡ï¼ˆé‡è¦ï¼ç‚ºäºŒæ‰‹è½‰å”®æº–å‚™ï¼‰
    
    åƒæ•¸:
        product_code: å•†å“ä»£ç¢¼ (ä¾‹å¦‚: GRL-S3225)
        color_code: é¡è‰²ä»£ç¢¼ (01, 02, 03...)
        high_quality: æ˜¯å¦è¿”å›é«˜ç•«è³ªç‰ˆæœ¬
    
    è¿”å›:
        åœ–ç‰‡ URL
        
    ç¯„ä¾‹:
        >>> construct_image_url_from_product_code("GRL-S3225", "01")
        'https://img.grail.bz/item/GRL-S3225/col_01.jpg'
    """
    base_url = "https://img.grail.bz/item"
    
    if high_quality:
        img_url = f"{base_url}/{product_code}/col_{color_code}.jpg"
    else:
        img_url = f"{base_url}/{product_code}/col_{color_code}_300x300.jpg"
    
    return img_url


def extract_color_code_from_url(img_url: str) -> Optional[str]:
    """
    å¾åœ–ç‰‡ URL ä¸­æå–é¡è‰²ä»£ç¢¼
    
    åƒæ•¸:
        img_url: åœ–ç‰‡ URL
    
    è¿”å›:
        é¡è‰²ä»£ç¢¼ (ä¾‹å¦‚: "01", "02") æˆ– None
        
    ç¯„ä¾‹:
        >>> extract_color_code_from_url("https://img.grail.bz/item/GRL-S3225/col_01.jpg")
        '01'
    """
    match = re.search(r'col_(\d+)', img_url)
    return match.group(1) if match else None


def generate_image_filename(product_code: str, color: str, index: int = 1, extension: str = "jpg") -> str:
    """
    ç”Ÿæˆæ¨™æº–åŒ–çš„åœ–ç‰‡æª”å
    
    åƒæ•¸:
        product_code: å•†å“ä»£ç¢¼
        color: é¡è‰²åç¨±ï¼ˆä¸­æ–‡æˆ–æ—¥æ–‡ï¼‰
        index: åœ–ç‰‡åºè™Ÿ
        extension: æª”æ¡ˆå‰¯æª”å
    
    è¿”å›:
        æª”å (ä¾‹å¦‚: GRL-S3225_black_01.jpg)
    """
    # æ¸…ç†é¡è‰²åç¨±ï¼ˆç§»é™¤æ‹¬è™Ÿå’Œç‰¹æ®Šå­—ç¬¦ï¼‰
    clean_color = re.sub(r'[ï¼ˆï¼‰\(\)]', '_', color).replace(' ', '_')
    filename = f"{product_code}_{clean_color}_{index:02d}.{extension}"
    return filename


def download_image(
    img_url: str,
    save_path: Path,
    force_download: bool = False
) -> Dict[str, any]:
    """
    ä¸‹è¼‰åœ–ç‰‡åˆ°æœ¬åœ°
    
    åƒæ•¸:
        img_url: åœ–ç‰‡ URL
        save_path: å„²å­˜è·¯å¾‘
        force_download: æ˜¯å¦å¼·åˆ¶é‡æ–°ä¸‹è¼‰ï¼ˆè¦†è“‹å·²å­˜åœ¨çš„æª”æ¡ˆï¼‰
    
    è¿”å›:
        ä¸‹è¼‰çµæœå­—å…¸ {'success': bool, 'path': str, 'size': int, 'message': str}
    """
    # å¦‚æœæª”æ¡ˆå·²å­˜åœ¨ä¸”ä¸å¼·åˆ¶ä¸‹è¼‰ï¼Œè·³é
    if save_path.exists() and not force_download:
        file_size = save_path.stat().st_size
        return {
            "success": True,
            "path": str(save_path),
            "size": file_size,
            "message": f"åœ–ç‰‡å·²å­˜åœ¨ï¼Œè·³éä¸‹è¼‰ ({file_size / 1024:.1f} KB)"
        }
    
    try:
        headers = {
            "User-Agent": "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36"
        }
        
        response = requests.get(img_url, headers=headers, timeout=30)
        response.raise_for_status()
        
        # ç¢ºä¿çˆ¶ç›®éŒ„å­˜åœ¨
        save_path.parent.mkdir(parents=True, exist_ok=True)
        
        # å¯«å…¥æª”æ¡ˆ
        with open(save_path, 'wb') as f:
            f.write(response.content)
        
        file_size = save_path.stat().st_size
        
        return {
            "success": True,
            "path": str(save_path),
            "size": file_size,
            "message": f"âœ… ä¸‹è¼‰æˆåŠŸ ({file_size / 1024:.1f} KB)"
        }
        
    except requests.exceptions.RequestException as e:
        return {
            "success": False,
            "path": str(save_path),
            "size": 0,
            "message": f"âŒ ä¸‹è¼‰å¤±æ•—: {str(e)}"
        }


def download_product_images(
    product_code: str,
    color_images: List[Dict],
    save_to_backup: bool = True
) -> Dict[str, any]:
    """
    ä¸‹è¼‰å•†å“çš„æ‰€æœ‰é¡è‰²åœ–ç‰‡ï¼ˆé«˜ç•«è³ªç‰ˆæœ¬ï¼‰
    
    åƒæ•¸:
        product_code: å•†å“ä»£ç¢¼
        color_images: é¡è‰²åœ–ç‰‡åˆ—è¡¨ [{"color": "é»‘è‰²", "image_url": "..."}]
        save_to_backup: æ˜¯å¦åŒæ™‚å‚™ä»½åˆ° backup ç›®éŒ„
    
    è¿”å›:
        ä¸‹è¼‰çµæœå­—å…¸
    """
    ensure_image_directories()
    
    results = {
        "product_code": product_code,
        "total_colors": len(color_images),
        "downloaded": 0,
        "failed": 0,
        "details": []
    }
    
    for idx, color_data in enumerate(color_images, 1):
        color_name = color_data.get("color", f"color_{idx}")
        img_url = color_data.get("image_url", "")
        
        # å‡ç´šç‚ºé«˜ç•«è³ª URL
        hq_url = upgrade_image_url_to_high_quality(img_url)
        
        # ç”Ÿæˆæª”å
        filename = generate_image_filename(product_code, color_name, idx)
        
        # ä¸‹è¼‰åˆ°å¿«å–ç›®éŒ„
        cache_path = IMAGE_CACHE_DIR / product_code / filename
        result_cache = download_image(hq_url, cache_path)
        
        # å¯é¸ï¼šå‚™ä»½åˆ° backup ç›®éŒ„
        if save_to_backup and result_cache["success"]:
            backup_path = IMAGE_BACKUP_DIR / product_code / filename
            result_backup = download_image(hq_url, backup_path, force_download=False)
        
        # è¨˜éŒ„çµæœ
        results["details"].append({
            "color": color_name,
            "original_url": img_url,
            "high_quality_url": hq_url,
            "local_path": result_cache.get("path"),
            "success": result_cache["success"],
            "message": result_cache["message"]
        })
        
        if result_cache["success"]:
            results["downloaded"] += 1
        else:
            results["failed"] += 1
        
        print(result_cache["message"])
    
    return results


def get_local_image_path(product_code: str, color: str, index: int = 1) -> Optional[Path]:
    """
    ç²å–æœ¬åœ°å¿«å–åœ–ç‰‡è·¯å¾‘ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    
    åƒæ•¸:
        product_code: å•†å“ä»£ç¢¼
        color: é¡è‰²åç¨±
        index: åœ–ç‰‡åºè™Ÿ
    
    è¿”å›:
        æœ¬åœ°åœ–ç‰‡è·¯å¾‘ï¼ˆPath ç‰©ä»¶ï¼‰æˆ– None
    """
    filename = generate_image_filename(product_code, color, index)
    cache_path = IMAGE_CACHE_DIR / product_code / filename
    
    return cache_path if cache_path.exists() else None


def cleanup_old_cache(days: int = 30) -> Dict[str, int]:
    """
    æ¸…ç†èˆŠçš„å¿«å–åœ–ç‰‡ï¼ˆå¯é¸åŠŸèƒ½ï¼‰
    
    åƒæ•¸:
        days: ä¿ç•™æœ€è¿‘ N å¤©çš„åœ–ç‰‡
    
    è¿”å›:
        æ¸…ç†çµ±è¨ˆ {'deleted_files': int, 'freed_space': int}
    """
    if not IMAGE_CACHE_DIR.exists():
        return {"deleted_files": 0, "freed_space": 0}
    
    now = datetime.now().timestamp()
    cutoff_time = now - (days * 24 * 60 * 60)
    
    deleted_count = 0
    freed_space = 0
    
    for img_file in IMAGE_CACHE_DIR.rglob("*.jpg"):
        if img_file.stat().st_mtime < cutoff_time:
            file_size = img_file.stat().st_size
            img_file.unlink()
            deleted_count += 1
            freed_space += file_size
            print(f"ğŸ—‘ï¸ åˆªé™¤èˆŠå¿«å–: {img_file.name}")
    
    return {
        "deleted_files": deleted_count,
        "freed_space": freed_space
    }


# ========================================
# é›²ç«¯å‚™ä»½åŠŸèƒ½ï¼ˆCloudinary/Imgurï¼‰
# ========================================

def upload_to_cloudinary(image_path: Path, product_code: str) -> Optional[str]:
    """
    ä¸Šå‚³åœ–ç‰‡åˆ° Cloudinaryï¼ˆéœ€å®‰è£ cloudinary å¥—ä»¶ï¼‰
    
    åƒæ•¸:
        image_path: æœ¬åœ°åœ–ç‰‡è·¯å¾‘
        product_code: å•†å“ä»£ç¢¼
    
    è¿”å›:
        é›²ç«¯åœ–ç‰‡ URL æˆ– None
    """
    try:
        import cloudinary
        import cloudinary.uploader
        
        # éœ€è¦åœ¨ .env è¨­å®š CLOUDINARY_* ç’°å¢ƒè®Šæ•¸
        result = cloudinary.uploader.upload(
            str(image_path),
            folder=f"wardrobe/{product_code}",
            use_filename=True
        )
        
        return result.get("secure_url")
        
    except ImportError:
        print("âš ï¸ æœªå®‰è£ cloudinary å¥—ä»¶ï¼Œè·³éé›²ç«¯å‚™ä»½")
        return None
    except Exception as e:
        print(f"âŒ Cloudinary ä¸Šå‚³å¤±æ•—: {e}")
        return None


def upload_to_imgur(image_path: Path) -> Optional[str]:
    """
    ä¸Šå‚³åœ–ç‰‡åˆ° Imgurï¼ˆéœ€è¦ Imgur API keyï¼‰
    
    åƒæ•¸:
        image_path: æœ¬åœ°åœ–ç‰‡è·¯å¾‘
    
    è¿”å›:
        Imgur åœ–ç‰‡ URL æˆ– None
    """
    IMGUR_CLIENT_ID = os.getenv("IMGUR_CLIENT_ID")
    
    if not IMGUR_CLIENT_ID:
        print("âš ï¸ æœªè¨­å®š IMGUR_CLIENT_IDï¼Œè·³é Imgur ä¸Šå‚³")
        return None
    
    try:
        with open(image_path, 'rb') as f:
            response = requests.post(
                "https://api.imgur.com/3/image",
                headers={"Authorization": f"Client-ID {IMGUR_CLIENT_ID}"},
                files={"image": f}
            )
        
        if response.status_code == 200:
            data = response.json()
            return data["data"]["link"]
        else:
            print(f"âŒ Imgur ä¸Šå‚³å¤±æ•—: {response.status_code}")
            return None
            
    except Exception as e:
        print(f"âŒ Imgur ä¸Šå‚³éŒ¯èª¤: {e}")
        return None


# ========================================
# æ¸¬è©¦èˆ‡ä½¿ç”¨ç¯„ä¾‹
# ========================================

if __name__ == "__main__":
    # æ¸¬è©¦åœ–ç‰‡ URL å‡ç´š
    test_url = "https://img.grail.bz/item/GRL-S3225/col_01_150x150.jpg"
    hq_url = upgrade_image_url_to_high_quality(test_url)
    print(f"åŸå§‹: {test_url}")
    print(f"é«˜ç•«è³ª: {hq_url}")
    
    # æ¸¬è©¦æ§‹å»º URL
    url = construct_image_url_from_product_code("GRL-S3225", "01")
    print(f"æ§‹å»º URL: {url}")
    
    # æ¸¬è©¦ä¸‹è¼‰ï¼ˆå–æ¶ˆè¨»è§£ä»¥å¯¦éš›æ¸¬è©¦ï¼‰
    # ensure_image_directories()
    # test_path = IMAGE_CACHE_DIR / "test.jpg"
    # result = download_image(hq_url, test_path)
    # print(result)
